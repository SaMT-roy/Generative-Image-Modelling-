{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5328aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 21:38:17.003367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance shape: (32,)\n",
      "first 3 values : [0.14032242 0.11136191 0.13181928]\n"
     ]
    }
   ],
   "source": [
    "import os, urllib.request, urllib.error\n",
    "import tensorflow as tf\n",
    "\n",
    "_URL = \"https://rail.eecs.berkeley.edu/models/lpips\"\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "def _get_pb(model='net-lin', net='alex', version='0.1'):\n",
    "    fname = f\"{model}_{net}_v{version}.pb\"\n",
    "    cache_dir = os.path.expanduser(\"~/.lpips\")\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    url = f\"{_URL}/{fname}\"\n",
    "    dst = os.path.join(cache_dir, fname)\n",
    "    if not os.path.isfile(dst):                         # download once\n",
    "        try:\n",
    "            tf.keras.utils.get_file(fname, origin=url, cache_dir=cache_dir,\n",
    "                                     cache_subdir='', file_hash=None)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            raise FileNotFoundError(f\"Could not download {url}\\n{e}\") from None\n",
    "    return dst\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "_lpips_cache = {}        # keeps one wrapped graph per (model, net, ver) combo\n",
    "def _get_lpips_fn(model='net-lin', net='alex', version='0.1'):\n",
    "    key = (model, net, version)\n",
    "    if key in _lpips_cache:                 # already wrapped → re-use\n",
    "        return _lpips_cache[key]\n",
    "\n",
    "    pb_path = _get_pb(model, net, version)\n",
    "\n",
    "    # 1. read frozen graph\n",
    "    with tf.io.gfile.GFile(pb_path, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # 2. import it inside wrap_function so it runs in graph mode\n",
    "    def _imports():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    wrapped = tf.compat.v1.wrap_function(_imports, [])   # no inputs yet\n",
    "\n",
    "    # 3. pick out placeholders & output, then “prune” → creates callable\n",
    "    g = wrapped.graph\n",
    "    x_ph   = g.get_tensor_by_name(\"0:0\")                 # input 1 (NCHW)\n",
    "    y_ph   = g.get_tensor_by_name(\"1:0\")                 # input 2 (NCHW)\n",
    "    out_t  = g.get_tensor_by_name(g.get_operations()[-1].name + \":0\")\n",
    "    lpips_fn = wrapped.prune([x_ph, y_ph], [out_t])      # callable(x, y) → dist\n",
    "\n",
    "    _lpips_cache[key] = lpips_fn\n",
    "    return lpips_fn\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def lpips_tf2(input0, input1, model='net-lin', net='alex', version='0.1'):\n",
    "    \"\"\"\n",
    "    LPIPS distance in TF-2 eager mode. Inputs NHWC in [0,1]; output shape matches\n",
    "    the leading batch dims (…,).\n",
    "    \"\"\"\n",
    "    # --- reshape leading dims, →NCHW, scale to [-1,1] ------------------------\n",
    "    leading_shape = tf.shape(input0)[:-3]                             # [...]\n",
    "    x = tf.reshape(input0,\n",
    "                   tf.concat([[-1], tf.shape(input0)[-3:]], axis=0))   # [N,H,W,C]\n",
    "    y = tf.reshape(input1,\n",
    "                   tf.concat([[-1], tf.shape(input1)[-3:]], axis=0))\n",
    "    x = tf.transpose(x, [0, 3, 1, 2]) * 2. - 1.                       # [N,C,H,W]\n",
    "    y = tf.transpose(y, [0, 3, 1, 2]) * 2. - 1.\n",
    "\n",
    "    # --- call wrapped frozen graph -----------------------------------------\n",
    "    lpips_fn = _get_lpips_fn(model, net, version)      # eager callable\n",
    "    dist = lpips_fn(x, y)[0]                           # returns tuple\n",
    "\n",
    "    # squeeze & restore leading dims\n",
    "    if dist.shape.ndims == 4:\n",
    "        dist = tf.squeeze(dist, axis=[-3, -2, -1])     # [N]\n",
    "    return tf.reshape(dist, leading_shape)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------- quick test --------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    tf.random.set_seed(0)\n",
    "    img0 = tf.random.uniform((32, 64, 64, 3), dtype=tf.float32)  # [0,1]\n",
    "    img1 = tf.random.uniform((32, 64, 64, 3), dtype=tf.float32)\n",
    "    d = lpips_tf2(img0, img1)        # eager call\n",
    "    print(\"distance shape:\", d.shape)  # (32,)\n",
    "    print(\"first 3 values :\", d.numpy()[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4e9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Extraas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
